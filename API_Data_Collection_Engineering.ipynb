{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06979c8f-2108-4e21-9bac-b78be52db192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed for API access, data retrieval and data cleaning\n",
    "import requests, json, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sqlite3\n",
    "import warnings\n",
    "\n",
    "from my_functions import *  # import all my custom functions needed to calc df transformations\n",
    "from quickfs import QuickFS\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4da0e3-a120-4169-a4ac-ec12901e896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain the ability to see all rows/columns if desired\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1f629de-3cab-4f8a-8748-249715260a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import api key and header for api access to quickfs.net\n",
    "api_key = os.environ['QFS_KEY']\n",
    "header = {'x-qfs-api-key': api_key}\n",
    "client = QuickFS(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c5010a-35f2-4a3d-8025-107815a93a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print all column names without quotes\n",
    "# print(*final_df.columns, sep=', ')\n",
    "# final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d879f7b2-05f4-45f1-8c7e-642fe7a2a8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stocks_table']\n",
      "['leaders_table']\n"
     ]
    }
   ],
   "source": [
    "# create the stocks sql database\n",
    "engineStocks = create_engine(\"sqlite:///stocks.db\", echo = False)\n",
    "engineLeaders = create_engine(\"sqlite:///leaders.db\", echo = False)\n",
    "# connect to the stocks sql database\n",
    "connStocks = sqlite3.connect('stocks.db')\n",
    "connLeaders = sqlite3.connect('leaders.db')\n",
    "# create the ability to perform logic on the database\n",
    "s = connStocks.cursor()\n",
    "l = connLeaders.cursor()\n",
    "# create the stock table in the stocks database\n",
    "s.execute('CREATE TABLE IF NOT EXISTS stocks_table '\\\n",
    "          '(Ticker TEXT, Name TEXT, Industry TEXT, Exchange TEXT, Market_Cap TEXT, Filing_Date TEXT, Q_End TEXT, '\\\n",
    "          'QNG_EPS INTEGER, QG_EPS INTEGER, QRev INTEGER, QRNG_EPS INTEGER, QRG_EPS INTEGER, QR_Rev INTEGER, '\\\n",
    "          'Q1_1 TEXT, Q1_2 TEXT, Q1_3 TEXT, Q2_1 TEXT, Q2_2 TEXT, Q2_3 TEXT, QS_1 TEXT, QS_2 TEXT, QS_3 TEXT, '\\\n",
    "          'R1_1 TEXT, R1_2 TEXT, R1_3 TEXT, R2_1 TEXT, R2_2 TEXT, R2_3 TEXT, RS_1 TEXT, RS_2 TEXT, RS_3 TEXT, '\\\n",
    "          'T1 TEXT, T2 TEXT, RT1 TEXT, RT2 TEXT, Q1 TEXT, Q2 TEXT, S TEXT, R1 TEXT, R2 TEXT, RS TEXT, '\\\n",
    "          'BO1 TEXT, BO2 TEXT, BOS TEXT, Total TEXT, '\\\n",
    "          'PRIMARY KEY (Ticker, Name, Industry, Exchange, Market_Cap, Filing_Date, Q_End, QNG_EPS, QG_EPS, QRev, '\\\n",
    "          'QRNG_EPS, QRG_EPS, QR_Rev, Q1_1, Q1_2, Q1_3, Q2_1, Q2_2, Q2_3, QS_1, QS_2, QS_3, R1_1, R1_2, R1_3, R2_1, R2_2, R2_3, '\\\n",
    "          'RS_1, RS_2, RS_3, T1, T2, RT1, RT2, Q1, Q2, S, R1, R2, RS, BO1, BO2, BOS, Total))')\n",
    "l.execute('CREATE TABLE IF NOT EXISTS leaders_table '\\\n",
    "          '(Ticker TEXT, Name TEXT, Industry TEXT, Exchange TEXT, Market_Cap TEXT, Filing_Date TEXT, Q_End TEXT, '\\\n",
    "          'QNG_EPS INTEGER, QG_EPS INTEGER, QRev INTEGER, QRNG_EPS INTEGER, QRG_EPS INTEGER, QR_Rev INTEGER, '\\\n",
    "          'Q1_1 TEXT, Q1_2 TEXT, Q1_3 TEXT, Q2_1 TEXT, Q2_2 TEXT, Q2_3 TEXT, QS_1 TEXT, QS_2 TEXT, QS_3 TEXT, '\\\n",
    "          'R1_1 TEXT, R1_2 TEXT, R1_3 TEXT, R2_1 TEXT, R2_2 TEXT, R2_3 TEXT, RS_1 TEXT, RS_2 TEXT, RS_3 TEXT, '\\\n",
    "          'T1 TEXT, T2 TEXT, RT1 TEXT, RT2 TEXT, Q1 TEXT, Q2 TEXT, S TEXT, R1 TEXT, R2 TEXT, RS TEXT, '\\\n",
    "          'BO1 TEXT, BO2 TEXT, BOS TEXT, Total TEXT, '\\\n",
    "          'PRIMARY KEY (Ticker, Name, Industry, Exchange, Market_Cap, Filing_Date, Q_End, QNG_EPS, QG_EPS, QRev, '\\\n",
    "          'QRNG_EPS, QRG_EPS, QR_Rev, Q1_1, Q1_2, Q1_3, Q2_1, Q2_2, Q2_3, QS_1, QS_2, QS_3, R1_1, R1_2, R1_3, R2_1, R2_2, R2_3, '\\\n",
    "          'RS_1, RS_2, RS_3, T1, T2, RT1, RT2, Q1, Q2, S, R1, R2, RS, BO1, BO2, BOS, Total))')\n",
    "# commit the stock table\n",
    "connStocks.commit()\n",
    "connLeaders.commit()\n",
    "# check the stock table and make sure it was correctly added to the database\n",
    "print(inspect(engineStocks).get_table_names())\n",
    "print(inspect(engineLeaders).get_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15ef03f-396d-4df7-bd4b-e18b981ae002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quota': {'used': 0, 'remaining': 25000, 'resets': '2021-10-23T23:00:00Z'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print total usage that day\n",
    "client.get_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2faa1c9-34f1-4a90-adb4-ed9e5f4f7c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get a list of all stocks that QuickFS has on the NYSE\n",
    "# nyse_list = client.get_supported_companies(country='US', exchange='NYSE')\n",
    "# new_nyse_list = []\n",
    "# for i in nyse_list:\n",
    "#     new_nyse_list.append(i.split(':')[0])\n",
    "# new_nyse_list = sorted(new_nyse_list)\n",
    "\n",
    "## get a list of all stocks that QuickFS has on the NASDAQ\n",
    "# nasdaq_list = client.get_supported_companies(country='US', exchange='NASDAQ')\n",
    "# new_nasdaq_list = []\n",
    "# for i in nasdaq_list:\n",
    "#     new_nasdaq_list.append(i.split(':')[0])\n",
    "# new_nasdaq_list = sorted(new_nasdaq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833cb83d-fa6a-4d1c-b157-95678cb3e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv('StockList.csv')\n",
    "stock_list = csv_df['Symbol'].tolist()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d82d8b-f56b-4ec7-984f-90b80bfdb035",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a count to keep track of stocks accessed\n",
    "count = 0\n",
    "# time how long it takes for the code to run\n",
    "start_time = time.time()\n",
    "# for loop to run through all stocks \n",
    "for i in stock_list:\n",
    "    ticker = i\n",
    "    country = 'US'\n",
    "\n",
    "    # the api json request structure\n",
    "    request_body = {\n",
    "        \"data\" : {\n",
    "            \"name\" : {\n",
    "                \"Name\" : \"QFS(\"+ticker+\":\"+country+\",name)\"\n",
    "             },\n",
    "            \"industry\" : {\n",
    "                \"Industry\" : \"QFS(\"+ticker+\":\"+country+\",industry)\"\n",
    "             }, \n",
    "            \"exchange\" : {\n",
    "                \"Exchange\": \"QFS(\"+ticker+\":\"+country+\",exchange)\"\n",
    "            },\n",
    "            \"mkt_cap\" : {\n",
    "                \"Market_Cap\": \"QFS(\"+ticker+\":\"+country+\",mkt_cap)\"\n",
    "            },\n",
    "            \"filing_date\" : {\n",
    "                \"Filing_Date\": \"QFS(\"+ticker+\":\"+country+\",original_filing_date,FQ:FQ)\"\n",
    "            },\n",
    "            \"q_end\" : {\n",
    "                \"Q_End\": \"QFS(\"+ticker+\":\"+country+\",period_end_date,FQ:FQ)\"\n",
    "            },\n",
    "            \"q_revenue\" : {\n",
    "                \"Q_Revenue\": \"QFS(\"+ticker+\":\"+country+\",revenue,FQ:FQ)\"\n",
    "            },\n",
    "            \"q_net_income\" : {\n",
    "                \"Q_Net_Inc\": \"QFS(\"+ticker+\":\"+country+\",net_income,FQ:FQ)\"\n",
    "            },\n",
    "            \"q_net_income_shareholders\" : {\n",
    "                \"Q_Net_Inc_Avail_To_Common\": \"QFS(\"+ticker+\":\"+country+\",net_income_available_to_shareholders,FQ:FQ)\"\n",
    "            },\n",
    "            \"q_shares_diluted\" : {\n",
    "                \"Q_Dil_Share_Outs\": \"QFS(\"+ticker+\":\"+country+\",shares_diluted,FQ:FQ)\"\n",
    "            },\n",
    "            \"q_ebitda\" : {\n",
    "                \"Q_EBITDA\": \"QFS(\"+ticker+\":\"+country+\",ebitda,FQ:FQ)\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    r = requests.post(\"https://public-api.quickfs.net/v1/data/batch\",json=request_body,headers=header)\n",
    "    print(r.status_code, r.reason)\n",
    "    print(ticker)\n",
    "    if r.status_code == 200:\n",
    "        # if status_code is normal, clean and insert data into data base\n",
    "        my_data = r.json()\n",
    "        # normalize the data (really 'flatten' the data) so it can be operated on\n",
    "        temp_df = pd.json_normalize(my_data)\n",
    "        # rename all columns\n",
    "        new_columns = []\n",
    "        [new_columns.append(i.split('.')[2]) for i in temp_df.columns]\n",
    "        temp_df.columns = new_columns\n",
    "        # reverse the rows of the data frame\n",
    "        temp_df.insert(0, 'Ticker', ticker)\n",
    "        temp_df = temp_df.apply(pd.Series.explode)\n",
    "        temp_df = temp_df.iloc[::-1].reset_index(drop=True)\n",
    "        # transform mrkt_cap column from num to str identifier\n",
    "        temp_df['Market_Cap'] = temp_df['Market_Cap'].apply(mrk_cap)\n",
    "        # create percent change columns for EPS G/NG, Rev and Profit Marg. G/NG\n",
    "        temp_df['QNG_EPS'] = percent_change(division(temp_df['Q_EBITDA'], temp_df['Q_Dil_Share_Outs']))\n",
    "        temp_df['QG_EPS'] = percent_change(division(temp_df['Q_Net_Inc_Avail_To_Common'], temp_df['Q_Dil_Share_Outs']))\n",
    "        temp_df['QRev'] = percent_change(temp_df['Q_Revenue'])\n",
    "        temp_df['QRNG_EPS'] = rolling_percent_change(division(temp_df['Q_EBITDA'], temp_df['Q_Dil_Share_Outs']))\n",
    "        temp_df['QRG_EPS'] = rolling_percent_change(division(temp_df['Q_Net_Inc_Avail_To_Common'], temp_df['Q_Dil_Share_Outs']))\n",
    "        temp_df['QR_Rev'] = rolling_percent_change(temp_df['Q_Revenue'])\n",
    "        temp_df['QNG_PM'] = subtraction(division(temp_df['Q_EBITDA'], temp_df['Q_Revenue']))\n",
    "        temp_df['QG_PM'] = subtraction(division(temp_df['Q_Net_Inc'], temp_df['Q_Revenue']))\n",
    "        temp_df['QRNG_PM'] = rolling_subtraction(division(temp_df['Q_EBITDA'], temp_df['Q_Revenue']))\n",
    "        temp_df['QRG_PM'] = rolling_subtraction(division(temp_df['Q_Net_Inc'], temp_df['Q_Revenue']))\n",
    "        # symbology to visually represent percent buckets per column percent change column\n",
    "        temp_df['Q1_1'] = eps_symbology1(temp_df['QNG_EPS'])\n",
    "        temp_df['Q1_2'] = eps_symbology2(temp_df['QNG_EPS'])\n",
    "        temp_df['Q1_3'] = eps_symbology3(temp_df['QNG_EPS'])\n",
    "        temp_df['Q2_1'] = eps_symbology1(temp_df['QG_EPS'])\n",
    "        temp_df['Q2_2'] = eps_symbology2(temp_df['QG_EPS'])\n",
    "        temp_df['Q2_3'] = eps_symbology3(temp_df['QG_EPS'])\n",
    "        temp_df['QS_1'] = rev_symbology1(temp_df['QRev'])\n",
    "        temp_df['QS_2'] = rev_symbology2(temp_df['QRev'])\n",
    "        temp_df['QS_3'] = rev_symbology3(temp_df['QRev'])\n",
    "        temp_df['R1_1'] = eps_symbology1(temp_df['QRNG_EPS'])\n",
    "        temp_df['R1_2'] = eps_symbology2(temp_df['QRNG_EPS'])\n",
    "        temp_df['R1_3'] = eps_symbology3(temp_df['QRNG_EPS'])\n",
    "        temp_df['R2_1'] = eps_symbology1(temp_df['QRG_EPS'])\n",
    "        temp_df['R2_2'] = eps_symbology2(temp_df['QRG_EPS'])\n",
    "        temp_df['R2_3'] = eps_symbology3(temp_df['QRG_EPS'])\n",
    "        temp_df['RS_1'] = rev_symbology1(temp_df['QR_Rev'])\n",
    "        temp_df['RS_2'] = rev_symbology2(temp_df['QR_Rev'])\n",
    "        temp_df['RS_3'] = rev_symbology3(temp_df['QR_Rev'])\n",
    "        # create all momentum indicator columns\n",
    "        ## tenets\n",
    "        temp_df['T1'] = tenet(temp_df['QNG_EPS'], temp_df['QRev'], temp_df['QNG_PM'])\n",
    "        temp_df['T2'] = tenet(temp_df['QG_EPS'], temp_df['QRev'], temp_df['QG_PM'])\n",
    "        temp_df['RT1'] = tenet(temp_df['QRNG_EPS'], temp_df['QR_Rev'], temp_df['QRNG_PM'])\n",
    "        temp_df['RT2'] = tenet(temp_df['QRG_EPS'], temp_df['QR_Rev'], temp_df['QRG_PM'])\n",
    "        ## momentum G/NG EPS, Rev\n",
    "        temp_df['Q1'] = momentum(temp_df['QNG_EPS'])\n",
    "        temp_df['Q2'] = momentum(temp_df['QG_EPS'])\n",
    "        temp_df['S'] = momentum(temp_df['QRev'])\n",
    "        temp_df['R1'] = momentum(temp_df['QRNG_EPS'])\n",
    "        temp_df['R2'] = momentum(temp_df['QRG_EPS'])\n",
    "        temp_df['RS'] = momentum(temp_df['QR_Rev'])\n",
    "        ## breakouts G/NG EPS, Rev\n",
    "        temp_df['BO1'] = breakout(temp_df['Q_EBITDA'], temp_df['Q_Dil_Share_Outs'])\n",
    "        temp_df['BO2'] = breakout(temp_df['Q_Net_Inc_Avail_To_Common'], temp_df['Q_Dil_Share_Outs'])\n",
    "        temp_df['BOS'] = sales_breakout(temp_df['Q_Revenue'])\n",
    "        # drop columns no longer needed\n",
    "        temp_df.drop(['Q_Revenue', 'Q_Net_Inc', 'Q_Net_Inc_Avail_To_Common', 'Q_Dil_Share_Outs', 'Q_EBITDA', \\\n",
    "                     'QNG_PM', 'QG_PM', 'QRNG_PM', 'QRG_PM'], axis=1, inplace=True)\n",
    "        # replace infinite ('inf') values\n",
    "        temp_df.replace(np.inf, '-', inplace=True)\n",
    "        # create an empty scores dataframe\n",
    "        score_df = pd.DataFrame()\n",
    "        # scoring\n",
    "        ## tenets\n",
    "        score_df['T1'] = tenet_score(temp_df['T1'])\n",
    "        score_df['T2'] = tenet_score(temp_df['T2'])\n",
    "        score_df['RT1'] = tenet_score(temp_df['RT1'])\n",
    "        score_df['RT2'] = tenet_score(temp_df['RT2'])\n",
    "        ## financials\n",
    "        score_df['NG'] = momentum_eps_score(temp_df['Q1'])\n",
    "        score_df['NG1'] = eps_q1_score(temp_df['QNG_EPS'])\n",
    "        score_df['NG2'] = eps_q2_score(temp_df['QNG_EPS'])\n",
    "        score_df['NG3'] = eps_q3_score(temp_df['QNG_EPS'])\n",
    "\n",
    "        score_df['G'] = momentum_eps_score(temp_df['Q2'])\n",
    "        score_df['G1'] = eps_q1_score(temp_df['QG_EPS'])\n",
    "        score_df['G2'] = eps_q2_score(temp_df['QG_EPS'])\n",
    "        score_df['G3'] = eps_q3_score(temp_df['QG_EPS'])\n",
    "\n",
    "        score_df['S'] = momentum_rev_score(temp_df['S'])\n",
    "        score_df['S1'] = rev_q1_score(temp_df['QRev'])\n",
    "        score_df['S2'] = rev_q2_score(temp_df['QRev'])\n",
    "        score_df['S3'] = rev_q3_score(temp_df['QRev'])\n",
    "\n",
    "        score_df['RNG'] = momentum_eps_score(temp_df['R1'])\n",
    "        score_df['RNG1'] = eps_q1_score(temp_df['QRNG_EPS'])\n",
    "        score_df['RNG2'] = eps_q2_score(temp_df['QRNG_EPS'])\n",
    "        score_df['RNG3'] = eps_q3_score(temp_df['QRNG_EPS'])\n",
    "\n",
    "        score_df['RG'] = momentum_eps_score(temp_df['R2'])\n",
    "        score_df['RG1'] = eps_q1_score(temp_df['QRG_EPS'])\n",
    "        score_df['RG2'] = eps_q2_score(temp_df['QRG_EPS'])\n",
    "        score_df['RG3'] = eps_q3_score(temp_df['QRG_EPS'])\n",
    "\n",
    "        score_df['RS'] = momentum_rev_score(temp_df['RS'])\n",
    "        score_df['RS1'] = rev_q1_score(temp_df['QR_Rev'])\n",
    "        score_df['RS2'] = rev_q2_score(temp_df['QR_Rev'])\n",
    "        score_df['RS3'] = rev_q3_score(temp_df['QR_Rev'])\n",
    "        ## breakouts\n",
    "        score_df['BOG'] = eps_breakout(temp_df['BO1'])\n",
    "        score_df['BONG'] = eps_breakout(temp_df['BO2'])\n",
    "        score_df['BOS'] = rev_breakout(temp_df['BOS'])\n",
    "        # produce the total score column\n",
    "        score_df['Total'] = round(score_df.sum(axis=1))\n",
    "        score_df['Total'].astype(int)\n",
    "        # isolate the final total column\n",
    "        score_df = score_df[['Total']]\n",
    "        # concat temp_df and score_df to create the final df\n",
    "        final_df = pd.concat([temp_df, score_df], axis=1)\n",
    "        # remove the last four rows which have no momentum data of which we can use\n",
    "        final_df.drop(final_df.tail(4).index, inplace=True)\n",
    "    else: continue\n",
    "    # add 1 to total count and print count\n",
    "    count += 1\n",
    "    # replace database if first pull, otherwise append data to its respective database\n",
    "    if count == 1:\n",
    "        final_df.to_sql('stocks_table', connStocks, if_exists='replace', index=False)\n",
    "    else:\n",
    "        final_df.to_sql('stocks_table', connStocks, if_exists='append', index=False)\n",
    "    if count == 1:\n",
    "        final_df.head(1).to_sql('leaders_table', connLeaders, if_exists='replace', index=False)\n",
    "    else:\n",
    "        final_df.head(1).to_sql('leaders_table', connLeaders, if_exists='append', index=False)\n",
    "    print(final_df.shape)\n",
    "    print(count)\n",
    "    \n",
    "print(\"This script took\", round((time.time() - start_time)/60, 2), \"minutes to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627980eb-c7d2-496a-bbdb-b90e8f903c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders = pd.read_sql_query('''SELECT * FROM \"leaders_table\"''', connLeaders)\n",
    "leaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16837e40-6bde-4ba7-8a80-332e0f56be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31432ec-ba8c-4b1e-b1ee-3fa1bc75d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_sql_query('''SELECT * FROM \"stocks_table\"''', connStocks)\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e66b99c0-d567-4d68-b469-af29ffd48137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111092, 45)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974fccd-675e-464e-95d8-577ed5c551d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
